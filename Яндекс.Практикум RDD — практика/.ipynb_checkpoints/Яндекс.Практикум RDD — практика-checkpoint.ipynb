{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "8837ccdf-2c57-423e-80aa-cdb7f09f1a5e"
    ]
   },
   "source": [
    "### RDD — практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext(\"local[*]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Ваш коллега так любит животных, что собрал у себя в загородном доме самых разных питомцев. Он пригласил вас и предложил решить задачу, какие виды животных у него обитают. Используйте метод RDD API, который покажет уникальные значения в этом RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Подсказка:* используйте метод `distinct()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кот', 'собака', 'рыбка', 'игуана']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pets = sc.parallelize(['кот', 'кот', 'собака', 'рыбка', 'рыбка', 'кот', 'кот', 'кот', \n",
    "                       'собака', 'кот', 'собака', 'рыбка', 'собака', 'рыбка', 'кот', \n",
    "                       'кот', 'рыбка', 'собака', 'рыбка', 'игуана','кот', 'кот', 'кот', \n",
    "                       'собака', 'рыбка', 'собака', 'рыбка', 'кот', 'кот', 'рыбка', 'собака'])\n",
    "\n",
    "pets_dist = pets.distinct()\n",
    "print(pets_dist.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Видов четыре, а животных гораздо больше. Поэтому коллега попросил вас найти всех котов и отфильтровать их в отдельный список, используя методы RDD API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Подсказка:* нужно применить метод `filter()` для значения `'кот'`, а затем получить список и распечатать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот', 'кот']\n"
     ]
    }
   ],
   "source": [
    "pets = pets.filter(lambda x: x == 'кот')\n",
    "print(pets.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Ваш друг вошёл во вкус и теперь просит посчитать, сколько у него рыбок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Подсказка:* примените метод `filter()` для значения `'рыбка'`, а затем метод `count()`, чтобы распечатать результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "pets = sc.parallelize(['кот', 'кот', 'собака', 'рыбка', 'рыбка', 'кот', 'кот', 'кот', \n",
    "                       'собака', 'кот', 'собака', 'рыбка', 'собака', 'рыбка', 'кот', \n",
    "                       'кот', 'рыбка', 'собака', 'рыбка', 'игуана','кот', 'кот', 'кот', \n",
    "                       'собака', 'рыбка', 'собака', 'рыбка', 'кот', 'кот', 'рыбка', 'собака'])\n",
    "\n",
    "pets = pets.filter(lambda x: x == 'рыбка')\n",
    "print(pets.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** В текстовом отрывке найдите топ-10 самых часто используемых слов. Нужно применить к тексту методы RDD API, которые разделят его на отдельные слова, посчитают количество упоминаний того или иного слова и отсортируют результаты в порядке убывания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Подсказка:* используйте метод `flatMap()`, чтобы разбить текст на слова, метод `map()` — чтобы назначить каждому слову 1, метод `reduceByKey()` — чтобы сложить упоминания тех или иных слов вместе. В конце нужно использовать метод `sortBy()`, чтобы отсортировать результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 26), ('a', 18), ('Spark', 15), ('of', 13), ('Apache', 8), ('is', 8), ('distributed', 8), ('for', 7), ('in', 7), ('data', 6)]\n"
     ]
    }
   ],
   "source": [
    "data = sc.textFile(\"/datasets/wiki_extract.txt\")\n",
    "\n",
    "word_counts = data.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
    "word_counts_sorted = word_counts.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "print(word_counts_sorted.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.** В топ-10 слов из прошлой задачи, помимо существительных, есть предлоги, артикли и другие части речи, которые не отображают суть отрывка. Ваша задача — почистить результат прошлой задачи, отфильтровав часто используемые слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Подсказка:* Используйте метод `map()`, чтобы применить функцию `clean_str_and_lower` к объекту data. Метод `flatMap()` поможет разбить текст на слова, `map()` — назначить каждому слову 1, `reduceByKey()` — сложить упоминания тех или иных слов вместе. А в конце обратитесь к методу `sortBy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark', 15), ('distributed', 9), ('apache', 8), ('data', 8), ('cluster', 6), ('rdd', 5), ('api', 5), ('dataset', 4), ('', 4), ('rdds', 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def clean_str_and_lower(x):\n",
    "    punc = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
    "    lowercase_str = x.lower()\n",
    "    for ch in punc:\n",
    "        lowercase_str = lowercase_str.replace(ch, '')\n",
    "    return lowercase_str\n",
    "\n",
    "\n",
    "data = sc.textFile(\"/datasets/wiki_extract.txt\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "word_counts = (\n",
    "    data\n",
    "    .map(clean_str_and_lower)\n",
    "    .flatMap(lambda x: x.split(' '))\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda x, y: x + y)\n",
    ")\n",
    "word_counts_sorted = word_counts.sortBy(lambda x: x[1], ascending=False)\n",
    "word_counts_filtered = word_counts_sorted.filter(lambda x: x[0] not in stop_words)\n",
    "\n",
    "print(word_counts_filtered.take(10))"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 30435,
    "start_time": "2022-01-19T19:22:03.077Z"
   },
   {
    "duration": 329,
    "start_time": "2022-01-19T19:22:36.111Z"
   },
   {
    "duration": 14628,
    "start_time": "2022-01-19T19:22:53.982Z"
   },
   {
    "duration": 97,
    "start_time": "2022-01-19T19:29:35.523Z"
   },
   {
    "duration": 608,
    "start_time": "2022-01-19T19:32:17.855Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-19T19:33:51.908Z"
   },
   {
    "duration": 3,
    "start_time": "2022-01-19T19:33:53.927Z"
   },
   {
    "duration": 14220,
    "start_time": "2023-10-07T18:29:50.837Z"
   },
   {
    "duration": 885,
    "start_time": "2023-10-07T18:30:56.575Z"
   },
   {
    "duration": 3979,
    "start_time": "2023-10-07T18:31:09.187Z"
   },
   {
    "duration": 11784,
    "start_time": "2023-10-07T18:31:55.366Z"
   },
   {
    "duration": 4610,
    "start_time": "2023-10-07T18:32:07.153Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-07T18:35:10.300Z"
   },
   {
    "duration": 86,
    "start_time": "2023-10-07T18:36:47.457Z"
   },
   {
    "duration": 76,
    "start_time": "2023-10-07T18:43:53.584Z"
   },
   {
    "duration": 731,
    "start_time": "2023-10-07T18:55:05.313Z"
   },
   {
    "duration": 353,
    "start_time": "2023-10-07T18:55:35.593Z"
   },
   {
    "duration": 155,
    "start_time": "2023-10-07T18:55:49.230Z"
   },
   {
    "duration": 445,
    "start_time": "2023-10-07T18:56:14.452Z"
   },
   {
    "duration": 108,
    "start_time": "2023-10-07T18:56:20.175Z"
   },
   {
    "duration": 101,
    "start_time": "2023-10-07T18:56:34.783Z"
   },
   {
    "duration": 283,
    "start_time": "2023-10-07T18:56:40.910Z"
   },
   {
    "duration": 96,
    "start_time": "2023-10-07T18:56:52.215Z"
   },
   {
    "duration": 239,
    "start_time": "2023-10-07T18:57:57.503Z"
   },
   {
    "duration": 168,
    "start_time": "2023-10-07T18:58:13.879Z"
   },
   {
    "duration": 204,
    "start_time": "2023-10-07T18:58:21.443Z"
   },
   {
    "duration": 153,
    "start_time": "2023-10-07T18:58:28.203Z"
   },
   {
    "duration": 1083,
    "start_time": "2023-10-07T19:02:51.157Z"
   },
   {
    "duration": 125,
    "start_time": "2023-10-07T19:03:04.935Z"
   },
   {
    "duration": 162,
    "start_time": "2023-10-07T19:03:28.424Z"
   },
   {
    "duration": 165,
    "start_time": "2023-10-07T19:03:39.369Z"
   },
   {
    "duration": 123,
    "start_time": "2023-10-07T19:03:43.656Z"
   },
   {
    "duration": 162,
    "start_time": "2023-10-07T19:03:47.409Z"
   },
   {
    "duration": 191,
    "start_time": "2023-10-07T19:03:50.496Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
