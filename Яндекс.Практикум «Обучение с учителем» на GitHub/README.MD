# Обучение с учителем  
[Проект](Яндекс.Практикум%20«Обучение%20с%20учителем»%20на%20GitHub.ipynb)  
# Постановка задачи:    
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет по предоставленным историческим данным о поведении клиентов и расторжении договоров с банком, а также построить модель с предельно большим значением F1-меры.  
# Навыки и инструменты:  
* **python**    
* **pandas**  
* **matplotlib**  
* **sklearn.dummy.DummyClassifier**  
* **sklearn.tree.DecisionTreeClassifier**   
* **sklearn.ensemble.RandomForestClassifier**   
* **sklearn.linear_model.LogisticRegression**  
# Общий вывод:  
**1) Мы подготовили данные:** 
- Были обнаружены нарушения правил хорошего стиля в названии столбцов
- В данных отсутствовали пропуски, кроме столбца `tenure`
- В данных отсутствовали несоответствия типов
- Практически все признаки имели околонулевую попарную корреляцию. Не было веских причин предполагать мультиколлинеарность в данных

**2) Мы провели предобработку данных:**
- Изменили названия столбцов в соответствии с правилами хорошего стиля
- Удалили признаки, которые не несут ценности для прогноза
- Заменили пропуски в столбце `tenure` на медианное значение
- Произвели OneHot кодирование
- Разделили исходные данные на обучающую, валидационную и тестовую выборки в соотношении 3:1:1

**3) Исследовали задачу:**
- В целевом признаке присутствовал явно выраженный дисбаланс классов
- Мы обучили модели `DecisionTreeClassifier`, `RandomForestClassifier`, `LogisticRegression` без учёта дисбаланса и проверили качество этих моделей на валидационной выборке. Мы использовали F1-меру в качестве метрики. Её значение оказалось меньше желаемого для всех обученных моделей (`< 0.59`)

**4) Обучили несколько различных моделей:**
- При помощи техники upsampling и взвешивания классов мы избавились от дисбаланса классов в целевом признаке
- Лучше всего показала себя модель `RandomForestClassifier` с гиперпараметрами `max_depth` — `10` и `n_estimators` — `54` с взвешиванием классов. Значение F1-меры у этой модели на валидационной выборке равно `0.6523`. Будем использовать её при конечном тестировании

**5) Протестировали наилучшую модель на тестовой выборке и проверили её на адекватность:**
- Наилучшая модель `RandomForestClassifier` успешно справилась с тестированием. Она показала значение F1-меры на тестовой выборке — `0.622` (> `0.59`)