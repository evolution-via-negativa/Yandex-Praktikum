{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cosmetic-isaac",
   "metadata": {},
   "source": [
    "В предыдущих уроках вы изучили BatchNorm и Dropout. Теперь пора посмотреть, как они работают.\n",
    "\n",
    "Поупражняйтесь на датасете рукописных цифр MNIST и убедитесь, что даже на одной эпохе BatchNorm улучшает качество модели. \n",
    "\n",
    "В этой задаче вы можете менять только класс модели. Исходный код дает точность ≈96.31% на тесте. С помощью BatchNorm можно её повысить до значения более 97%. \n",
    "\n",
    "В этой задаче нет одного правильного решения, вам нужно эксперементировать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-martial",
   "metadata": {},
   "source": [
    "# Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-being",
   "metadata": {},
   "source": [
    "Запустите исходный код, чтобы получить базовые результаты обучения модели (англ. *baseline*). Затем добавьте один или несколько слоёв BatchNorm (пример `nn.BatchNorm1d(num_inputs)`) в модель `NeuralNet` и сравните итоги работы модели с использованием этого метода и без.\n",
    "\n",
    "Кроме того, вы можете добавить слой Dropout (пример `nn.Dropout(p=0.5)`) и посмотреть, как он сочетается с BatchNorm. Так вы сможете понять, почему два этих метода не рекомендуется использовать одновременно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425ef5e",
   "metadata": {},
   "source": [
    "Установите необходимые пакеты. Возможно, после установки потребуется перезапустить ядро Jupyter через пункт меню Kernel -> Restart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2676e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.10.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.10.0%2Bcpu-cp39-cp39-linux_x86_64.whl (199.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.3 MB 14 kB/s  eta 0:00:011   |▏                               | 983 kB 21.4 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting torchvision==0.11.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.11.0%2Bcpu-cp39-cp39-linux_x86_64.whl (16.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.1 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.10.0\n",
      "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp39-cp39-linux_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.10.0+cpu) (4.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision==0.11.0+cpu) (1.21.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision==0.11.0+cpu) (8.4.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torch-1.10.0+cpu torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.0+cpu torchvision==0.11.0+cpu torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-garbage",
   "metadata": {},
   "source": [
    "Импортируйте необходимые пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-basement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T06:35:29.048471Z",
     "start_time": "2022-04-30T06:35:25.898607Z"
    },
    "tags": [
     "24a96b51-8991-4c48-a695-8d2bbf2cc7bc"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-mistress",
   "metadata": {},
   "source": [
    "Гиперпараметры обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "personalized-associate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T06:35:29.071212Z",
     "start_time": "2022-04-30T06:35:29.052051Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(1234)\n",
    "input_size = 28*28\n",
    "hidden_size = 800\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-western",
   "metadata": {},
   "source": [
    "Создайте датасет и даталоадер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protecting-tower",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T06:35:34.146981Z",
     "start_time": "2022-04-30T06:35:29.074704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4fc19c7977499a900dbd1528d87a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ee94aa30c342d69ae4ccd25db9bc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56834e6c795a400680e54b16792fc92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b7b48fed5450b9f198c13fbee15c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST датасет\n",
    "train_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Dataloader для тренировочной и тестовой части датасета \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-james",
   "metadata": {},
   "source": [
    "Создайте модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "active-minneapolis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T06:35:34.157420Z",
     "start_time": "2022-04-30T06:35:34.150601Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-binding",
   "metadata": {},
   "source": [
    "Обучение и проверка точности на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floral-chance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T06:35:46.224352Z",
     "start_time": "2022-04-30T06:35:34.161840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/1], Итерация [100/600], Значение функции потерь: 0.1703 Точность на батче: 93.0%\n",
      "Эпоха [1/1], Итерация [200/600], Значение функции потерь: 0.1062 Точность на батче: 99.0%\n",
      "Эпоха [1/1], Итерация [300/600], Значение функции потерь: 0.2211 Точность на батче: 92.0%\n",
      "Эпоха [1/1], Итерация [400/600], Значение функции потерь: 0.1790 Точность на батче: 96.0%\n",
      "Эпоха [1/1], Итерация [500/600], Значение функции потерь: 0.0615 Точность на батче: 98.0%\n",
      "Эпоха [1/1], Итерация [600/600], Значение функции потерь: 0.1268 Точность на батче: 98.0%\n",
      "Точность на тесте: 96.71 %\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # В качестве функции потерь используем Кросс-Энтропию\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # создаем Adam оптимизатор\n",
    "\n",
    "# Цикл обучения\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.reshape(-1, input_size)\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратный проход\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Эпоха [{}/{}], Итерация [{}/{}], Значение функции потерь: {:.4f} Точность на батче: {}%' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item(), 100 *(predicted == labels).sum()/labels.size(0)))\n",
    "\n",
    "# Считаем точность на тестовой выборке\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size)\n",
    "        labels = labels\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Точность на тесте: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d03384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 28605,
    "start_time": "2024-03-04T15:57:53.558Z"
   },
   {
    "duration": 1093,
    "start_time": "2024-03-04T15:58:29.547Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-04T15:58:32.834Z"
   },
   {
    "duration": 7192,
    "start_time": "2024-03-04T15:58:38.717Z"
   },
   {
    "duration": 3,
    "start_time": "2024-03-04T15:59:03.532Z"
   },
   {
    "duration": 18525,
    "start_time": "2024-03-04T15:59:10.092Z"
   },
   {
    "duration": 5,
    "start_time": "2024-03-04T16:26:15.715Z"
   },
   {
    "duration": 146,
    "start_time": "2024-03-04T16:26:16.428Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-04T16:28:47.709Z"
   },
   {
    "duration": 23845,
    "start_time": "2024-03-04T16:28:48.301Z"
   }
  ],
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
